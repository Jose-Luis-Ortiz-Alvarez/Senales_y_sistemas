{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jose-Luis-Ortiz-Alvarez/Senales_y_sistemas/blob/main/Serie_y_TransformadaFourier/Taller_youtube_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmaPHWwtvLHa"
      },
      "outputs": [],
      "source": [
        "#cargar datos desde drive acceso libre\n",
        "#https://docs.google.com/spreadsheets/d/1DcFvMqFZdtHViXmJGNKSr1zKi8fr4nZu/edit?usp=sharing&ouid=107935825643096281049&rtpof=true&sd=true\n",
        "FILEID = \"1DcFvMqFZdtHViXmJGNKSr1zKi8fr4nZu\"\n",
        "#\"1DcFvMqFZdtHViXmJGNKSr1zKi8fr4nZu\"\n",
        "\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O  canciones.xlsx && rm -rf /tmp/cookies.txt\n",
        "#!unzip -o codigos.zip\n",
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_ = 'canciones.xlsx'#leer archivo xlsx con link, band, type\n",
        "X  = pd.read_excel(file_)\n",
        "X#imprimir filas iniciales"
      ],
      "metadata": {
        "id": "NF9zfZdPv7JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instalar librerias necesarias para descargar audios youtube\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install soundfile\n",
        "\n",
        "import os\n",
        "import yt_dlp as youtube_dl\n",
        "\n",
        "#funcion para descargar mp3 desde youtube\n",
        "def download_ytvid_as_mp3(video_url,name):\n",
        "    #video_url = input(\"enter url of youtube video:\")\n",
        "    video_info = youtube_dl.YoutubeDL().extract_info(url = video_url,download=False)\n",
        "    filename = f\"{name}.mp3\"\n",
        "    options={\n",
        "        'format':'bestaudio/best',\n",
        "        'keepvideo':False,\n",
        "        'outtmpl':filename,\n",
        "    }\n",
        "\n",
        "    with youtube_dl.YoutubeDL(options) as ydl:\n",
        "        ydl.download([video_info['webpage_url']])\n",
        "\n",
        "    print(\"Download complete... {}\".format(filename))"
      ],
      "metadata": {
        "id": "-0GnJhn9wYpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "#crear carpeta con resultados\n",
        "try:\n",
        "  os.mkdir('results')\n",
        "except:\n",
        "  print(\"Carpeta results ya existe\")\n",
        "\n",
        "#recorrer excel con videos\n",
        "N, P = X.shape\n",
        "Ns = N * 5 #cantidad de segmentos por cancion\n",
        "\n",
        "for n in range(N):\n",
        "    print(f\"video {n+1} de {N}\")\n",
        "    print(f\"link: {X.loc[n,'link']}\\n\")\n",
        "    print(f\"band: {X.loc[n,'band']}\\n\")\n",
        "    print(f\"type: {X.loc[n,'type']}\\n\")\n",
        "    #ruta video n-th\n",
        "    name_ = 'results/'+X.loc[n,'band']+\"_\"+str(n)+\"_\"+str(X.loc[n,'type_num']) # #video+nombre+tipo de genero musical\n",
        "    #descargar mp3 desde youtube\n",
        "    download_ytvid_as_mp3(X.loc[n,'link'],name_)\n",
        "    #convertir a .wav\n",
        "    subprocess.call(['ffmpeg','-y', '-i', name_+'.mp3',\n",
        "                   name_+'.wav'])"
      ],
      "metadata": {
        "id": "8q0Xv9BcwzeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar .wavs y partir audios\n",
        "#lista archivos .wav\n",
        "path = 'results/'\n",
        "wav_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "wav_files"
      ],
      "metadata": {
        "id": "gX5bdp-7w--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile #instalar sondfile"
      ],
      "metadata": {
        "id": "rYfmNwVVzpF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf # para instalar pip install soundfile\n",
        "#leer archivos y crear np.array audios\n",
        "fs = 48000\n",
        "tl = np.array([40,50,60,70,80,90,100]) #puntos lectura\n",
        "ts = 5 #t segmento\n",
        "Ns = len(wav_files)*len(tl) #cantidad segmentos\n",
        "x_t = np.zeros((Ns,int(ts*fs),2)) #Ns segmentos, cantidad de muestras, 2 canales (stereo)\n",
        "label = np.zeros((Ns,1)) #vector tipo de genero\n",
        "name_c = []\n",
        "#leer archivos wav\n",
        "i = 0\n",
        "for name in wav_files:#lectura audio .wav\n",
        "    x, fs = sf.read(path+name)\n",
        "    for ti in tl: #segmentos de tiempo\n",
        "        x_t[i] = x[int(fs*ti):int(fs*(ti+ts)),:]\n",
        "        label[i] = int(name[-5]) #tipo de genero\n",
        "        name_c += [name[:-6]]\n",
        "        print(f\"{i} lectura: {name}; segundo {ti}:{ti+ts}; tipo música {label[i]}\")\n",
        "        i+=1\n",
        "x_t.shape"
      ],
      "metadata": {
        "id": "nOn4GrOkzZvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio #reproducir segmento\n",
        "i = 10\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "YM3ltcs6zOHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculo de fourier\n",
        "vf = np.fft.rfftfreq(x_t.shape[1],1/fs) #calculo vector de frecuencias\n",
        "Xw = np.fft.rfft(x_t,axis=1).mean(axis=-1) #transformada rapida de Fourier para señal Real a lo largo del tiempo (axis=1) y se promedian los dos canales\n",
        "Xw.shape"
      ],
      "metadata": {
        "id": "qcd1pUoz2KM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grafica tiempo y fourier\n",
        "plt.plot(np.arange(0,ts,1/fs),x_t.mean(axis=-1).T) #se promedian los dos canales stereo\n",
        "plt.xlabel('t[s]')\n",
        "plt.ylabel('x(t)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NiacFvIx4vpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(vf,abs(Xw).T)\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)|')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roZkalWc5cqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se normalizan espectros entre 0 y 1 para evitar inconsistencias por ampliltudes máximas\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sca = MinMaxScaler()\n",
        "Xw_ = sca.fit_transform(abs(Xw).T).T\n",
        "\n",
        "plt.plot(vf,Xw_.T)\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)|')\n",
        "plt.show()\n",
        "\n",
        "#en dB\n",
        "plt.plot(vf,(20*np.log10(Xw_+1e-10)).T) # se suma 1e-10 para evitar discontinuidad del log\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)| dB')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DR4Tw83c6b-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota**: Generalmente el espectro se presenta en [decibeles [dB]](https://es.wikipedia.org/wiki/Decibelio)"
      ],
      "metadata": {
        "id": "AXaYxHDVQj1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "#visualización de datos\n",
        "red_ = TSNE(perplexity = 20,n_components=2,random_state=123,learning_rate='auto',init='pca')\n",
        "#red_ = PCA(n_components=2,random_state=123)\n",
        "fmax = 7000\n",
        "X_2D = red_.fit_transform(Xw_[:,:fmax]) #se tiene en cuenta el espectro hasta fmax Hz"
      ],
      "metadata": {
        "id": "UZGVCWRk1eAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar separabilidad 2D\n",
        "plt.scatter(X_2D[:,0],X_2D[:,1],c=label)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "color_ = [\"b\",\"y\"]\n",
        "#nombre cancion\n",
        "plt.scatter(X_2D[:,0],X_2D[:,1],c=label,s=1)\n",
        "for i, tex in enumerate(name_c):\n",
        "    #print(f\"{i} {tex}\")\n",
        "    plt.text(X_2D[i,0]*1.025,X_2D[i,1]*1.025, tex[:-2]+\"_\"+str(i), fontsize=6,color=color_[int(label[i]-1)])\n",
        "\n",
        "#plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A2Tmfe-57ZEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reproducir audio\n",
        "i = 80\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "fubfCcH5CHzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 14\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "z9NRefvJD7Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "#guardar modelo\n",
        "os.mkdir('modelo')\n",
        "filename_ = 'modelo/Rock_vs_Pop'\n",
        "model_ ={'Xw_':Xw_,'fmax': fmax, 'label' : label, 'name_c' : name_c, 'vf':vf,'fs':fs}\n",
        "joblib.dump(model_,filename_+\".pkl\")\n"
      ],
      "metadata": {
        "id": "JFDhqdxH79cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#descargar modelo\n",
        "#guardar resultados\n",
        "from google.colab import files\n",
        "from datetime import date, datetime\n",
        "import shutil\n",
        "#guardar resultados\n",
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'modelo'\n",
        "shutil.make_archive(namefile, 'zip', 'modelo')\n",
        "files.download(namefile+'.zip')\n",
        "\n",
        "#el archivo .zip puede cargarse en drive y utilizarse en otro cuaderno para detectar género musical de nuevos segmentos"
      ],
      "metadata": {
        "id": "7zWJ8LNQBjNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar modelo\n",
        "my_model_loaded = joblib.load(filename_+\".pkl\")\n",
        "my_model_loaded.keys()"
      ],
      "metadata": {
        "id": "LRJ7txqCA1bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 1. DESCARGA DE CANCIONES DESDE EL EXCEL\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "# Identificador de tu Google Sheet con las 10 canciones\n",
        "FILEID = \"1DcFvMqFZdtHViXmJGNKSr1zKi8fr4nZu\"\n",
        "\n",
        "# Descargamos el Excel desde Google Drive\n",
        "!wget --load-cookies /tmp/cookies.txt \\\n",
        " \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet \\\n",
        "  --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \\\n",
        "  'https://docs.google.com/uc?export=download&id='$FILEID -O- | \\\n",
        "  sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID \\\n",
        "  -O canciones.xlsx && rm -rf /tmp/cookies.txt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import subprocess\n",
        "import yt_dlp as youtube_dl\n",
        "import soundfile as sf\n",
        "\n",
        "# Leemos el Excel que contiene: link, band, type, type_num\n",
        "X = pd.read_excel(\"canciones.xlsx\")\n",
        "\n",
        "# Creamos la carpeta donde guardaremos mp3 y wav\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Función para descargar un video de YouTube como MP3\n",
        "def download_ytvid_as_mp3(video_url, name):\n",
        "    video_info = youtube_dl.YoutubeDL().extract_info(url=video_url, download=False)\n",
        "    filename = f\"{name}.mp3\"\n",
        "    options = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'keepvideo': False,\n",
        "        'outtmpl': filename,\n",
        "    }\n",
        "    with youtube_dl.YoutubeDL(options) as ydl:\n",
        "        ydl.download([video_info['webpage_url']])\n",
        "    print(f\"Download complete: {filename}\")\n",
        "\n",
        "# Iteramos sobre las filas del Excel, descargamos y convertimos a WAV\n",
        "N = len(X)\n",
        "for n in range(N):\n",
        "    link  = X.loc[n, 'link']\n",
        "    band  = X.loc[n, 'band']\n",
        "    tnum  = X.loc[n, 'type_num']\n",
        "    name_ = f\"results/{band}_{n}_{tnum}\"\n",
        "    print(f\"\\n=== Descargando canción {n+1}/{N} ===\")\n",
        "    print(f\"Link: {link}\")\n",
        "    download_ytvid_as_mp3(link, name_)\n",
        "    # Convertimos el MP3 a WAV (48 kHz, estéreo si aplica)\n",
        "    subprocess.call([\n",
        "        'ffmpeg', '-y',\n",
        "        '-i', f\"{name_}.mp3\",\n",
        "        '-ar', '48000',   # sample rate 48 kHz\n",
        "        '-ac', '2',       # 2 canales estéreo\n",
        "        f\"{name_}.wav\"\n",
        "    ])\n",
        "    # Borramos el mp3 original para ahorrar espacio\n",
        "    os.remove(f\"{name_}.mp3\")\n",
        "\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 2. PARTICIONAR CADA WAV EN 5 FRAGMENTOS DE 5 SEGUNDOS → 50 MUESTRAS TOTALES\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "# Listamos todos los archivos .wav que acabamos de generar\n",
        "path = 'results/'\n",
        "wav_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "print(f\"\\nTotal de archivos WAV encontrados: {len(wav_files)} (deberían ser 10)\")\n",
        "\n",
        "# Parámetros de segmentación\n",
        "fs = 48000            # frecuencia de muestreo (48 kHz)\n",
        "ts = 5                # duración de cada segmento en segundos\n",
        "# Para obtener 50 segmentos en total a partir de 10 canciones,\n",
        "# necesitamos 5 offsets (5 segundos de duración) por cada canción:\n",
        "tl = [10,  40,  70, 100, 130]   # instantes (en segundos) donde empieza cada fragmento de 5 s\n",
        "\n",
        "Ns = len(wav_files) * len(tl)   # 10 canciones × 5 offsets = 50 segmentos\n",
        "# Preasignamos arrays:\n",
        "x_t    = np.zeros((Ns, int(ts*fs), 2), dtype=np.float32)  # Ns segmentos, muestras (5s×48kHz), 2 canales\n",
        "label  = np.zeros((Ns, 1),  dtype=int)                    # etiqueta de género (1 o 2)\n",
        "name_c = []                                               # nombre de canción (sin sufijo \"_n_type\")\n",
        "\n",
        "i = 0\n",
        "for name in wav_files:\n",
        "    filepath = os.path.join(path, name)\n",
        "    x, fs_file = sf.read(filepath)    # x.shape = (total_muestras, 2)\n",
        "    if fs_file != fs:\n",
        "        raise RuntimeError(f\"Esperamos 48 kHz, pero {name} está a {fs_file} Hz\")\n",
        "    # Etiqueta de género tomada del penúltimo carácter antes de \".wav\": \"..._{type}.wav\"\n",
        "    genre_num = int(name[-5])  # asumiendo formato \"..._{type}.wav\"\n",
        "    base_name = name[:-6]      # para evitar \"..._n_t.wav\"\n",
        "    for ti_seg in tl:\n",
        "        start = int(ti_seg * fs)\n",
        "        end   = int((ti_seg + ts) * fs)\n",
        "        x_t[i]   = x[start:end, :]      # recortamos 5 segundos (estéreo)\n",
        "        label[i] = genre_num\n",
        "        name_c.append(base_name)\n",
        "        print(f\"{i:02d} → {name}   segundos {ti_seg}:{ti_seg+ts}   género {genre_num}\")\n",
        "        i += 1\n",
        "\n",
        "print(f\"\\nForma de x_t: {x_t.shape}   → 50 segmentos de 5 s en estéreo\")\n",
        "print(f\"Forma de label: {label.shape}\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 3. CÁLCULO DE LA FFT Y NORMALIZACIÓN DE CADA SEGMENTO\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "# 3.A. Construimos el vector de frecuencias completo para rfft (para ts×fs muestras)\n",
        "vf = np.fft.rfftfreq(int(ts*fs), 1/fs)\n",
        "\n",
        "# 3.B. Calculamos la FFT real para cada segmento (axis=1 recorre el tiempo)\n",
        "#      Luego promediamos ambos canales en el dominio de magnitudes.\n",
        "Xw = np.fft.rfft(x_t, axis=1)          # shape = (50, N_bins, 2)\n",
        "Xw_mag = np.mean(np.abs(Xw), axis=2)   # shape = (50, N_bins)\n",
        "\n",
        "# 3.C. Escogemos un fmax razonable (p. ej. 7000 Hz) para recortar el espectro\n",
        "fmax = 7000\n",
        "fmax_idx = np.argmin(np.abs(vf - fmax))  # índice del bin más cercano a fmax\n",
        "print(f\"\\nBin máximo seleccionado (f <= {fmax} Hz):  {fmax_idx}  (f = {vf[fmax_idx]:.1f} Hz)\")\n",
        "\n",
        "# 3.D. Cortamos el espectro a [0 : fmax_idx]\n",
        "Xw_crop = Xw_mag[:, :fmax_idx]\n",
        "\n",
        "# 3.E. Normalizamos entre 0 y 1 cada vector de frecuencias\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sca = MinMaxScaler()\n",
        "Xw_norm = sca.fit_transform(Xw_crop)   # shape = (50, fmax_idx)\n",
        "\n",
        "print(f\"Dataset final de espectros normalizados:  {Xw_norm.shape}   (50 muestras × {fmax_idx} bins)\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 4. VISUALIZACIÓN RÁPIDA Y SEPARABILIDAD 2D\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 4.A. Graficar magnitud del primer segmento (solo para verificar)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(vf[:fmax_idx], Xw_norm[0], color='tab:blue')\n",
        "plt.title(\"Espectro normalizado (fragmento #0)\")\n",
        "plt.xlabel(\"Frecuencia [Hz]\")\n",
        "plt.ylabel(\"Magnitud normalizada\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 4.B. Separabilidad 2D usando TSNE\n",
        "red_ = TSNE(perplexity=20, n_components=2, random_state=123, learning_rate='auto', init='pca')\n",
        "X_2D = red_.fit_transform(Xw_norm)  # shape = (50, 2)\n",
        "\n",
        "# Graficar scatter con colorbar\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.scatter(X_2D[:,0], X_2D[:,1], c=label.ravel(), cmap='viridis', s=20)\n",
        "plt.colorbar(label=\"Género (1 vs 2)\")\n",
        "plt.title(\"Separabilidad 2D (TSNE) de los 50 segmentos\")\n",
        "plt.xlabel(\"Dim 1\")\n",
        "plt.ylabel(\"Dim 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Graficar scatter con nombres de canciones\n",
        "color_ = [\"b\", \"y\"]\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.scatter(X_2D[:,0], X_2D[:,1], c=label.ravel(), s=10, cmap='viridis')\n",
        "for idx, tex in enumerate(name_c):\n",
        "    plt.text(\n",
        "        X_2D[idx,0] * 1.025,\n",
        "        X_2D[idx,1] * 1.025,\n",
        "        tex.split('/')[-1],\n",
        "        fontsize=6,\n",
        "        color=color_[int(label[idx,0] - 1)]\n",
        "    )\n",
        "plt.title(\"Mapa 2D con etiquetas de canciones\")\n",
        "plt.xlabel(\"Dim 1\")\n",
        "plt.ylabel(\"Dim 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 5. ENTRENAMIENTO DEL CLASIFICADOR KNN (DISTANCIA EUCLÍDEA)\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "knn.fit(Xw_norm, label.ravel())\n",
        "\n",
        "os.makedirs('modelo', exist_ok=True)\n",
        "joblib.dump({\n",
        "    'knn_model': knn,\n",
        "    'scaler'   : sca,\n",
        "    'fmax_idx' : fmax_idx,\n",
        "    'vf'       : vf[:fmax_idx],\n",
        "    'fs'       : fs\n",
        "}, 'modelo/knn_genre_detector.pkl')\n",
        "\n",
        "print(\"\\n—> Entrenamiento completado: 50 vectores (5 s cada uno) con KNN guardado en modelo/knn_genre_detector.pkl\\n\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 6. CREAR UN FRAGMENTO DE PRUEBA EXTRAÍDO DE LOS 50 SEGMENTOS Y GUARDARLO COMO WAV\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "i_test = 32\n",
        "test_fragment = x_t[i_test]   # forma (240000, 2)\n",
        "sf.write(\"nuevo_fragmento_5s.wav\", test_fragment, fs)\n",
        "print(f\"→ Se creó 'nuevo_fragmento_5s.wav' a partir del segmento #{i_test} (género real = {int(label[i_test,0])})\\n\")\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 7. FUNCIÓN PARA DETECTAR GÉNERO DE UN NUEVO FRAGMENTO DE 5 s\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "def predict_genre_from_wav(new_wav_path: str, model_path: str = 'modelo/knn_genre_detector.pkl'):\n",
        "    \"\"\"\n",
        "    Carga un archivo WAV de exactamente 5 segundos (mono o estéreo),\n",
        "    calcula su FFT, recorta hasta fmax_idx, normaliza con el mismo MinMaxScaler\n",
        "    y predice el género usando el KNN entrenado.\n",
        "    Devuelve la etiqueta (1 o 2).\n",
        "    \"\"\"\n",
        "    mdl = joblib.load(model_path)\n",
        "    knn_loaded = mdl['knn_model']\n",
        "    sca_loaded = mdl['scaler']\n",
        "    fmax_idx  = mdl['fmax_idx']\n",
        "    fs_ref    = mdl['fs']\n",
        "\n",
        "    x5, fs_file = sf.read(new_wav_path)\n",
        "    if fs_file != fs_ref:\n",
        "        raise ValueError(f\"El WAV está a {fs_file} Hz; debe estar a {fs_ref} Hz.\")\n",
        "    n5 = 5 * fs_ref\n",
        "    if x5.ndim == 1:\n",
        "        if x5.shape[0] < n5:\n",
        "            raise ValueError(\"El archivo WAV es más corto de 5 segundos.\")\n",
        "        x5_seg = x5[:n5]\n",
        "    else:\n",
        "        if x5.shape[0] < n5:\n",
        "            raise ValueError(\"El WAV (estéreo) es más corto de 5 segundos.\")\n",
        "        x5_seg = x5[:n5, :]\n",
        "\n",
        "    if x5_seg.ndim == 1:\n",
        "        Xw5 = np.abs(np.fft.rfft(x5_seg))\n",
        "    else:\n",
        "        Xw5_0 = np.abs(np.fft.rfft(x5_seg[:, 0]))\n",
        "        Xw5_1 = np.abs(np.fft.rfft(x5_seg[:, 1]))\n",
        "        Xw5   = (Xw5_0 + Xw5_1) / 2.0\n",
        "\n",
        "    mag5_crop = Xw5[:fmax_idx].reshape(1, -1)\n",
        "    mag5_norm = sca_loaded.transform(mag5_crop)\n",
        "\n",
        "    pred = knn_loaded.predict(mag5_norm)[0]\n",
        "    return int(pred)\n",
        "\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "# 8. EJEMPLO DE USO DEL DETECTOR (SE PREDICE SOBRE 'nuevo_fragmento_5s.wav')\n",
        "# ——————————————————————————————————————————————————————————————————————————\n",
        "\n",
        "nuevo_fragmento = \"nuevo_fragmento_5s.wav\"  # creado en el paso anterior\n",
        "\n",
        "try:\n",
        "    genero_predicho = predict_genre_from_wav(nuevo_fragmento)\n",
        "    print(f\"\\n¡Género predicho para '{nuevo_fragmento}': {genero_predicho}  (2=Pop, 1=Rock)!\\n\")\n",
        "    display(Audio(nuevo_fragmento, rate=fs))\n",
        "except Exception as e:\n",
        "    print(\"Error al predecir género:\", e)"
      ],
      "metadata": {
        "id": "k2o30IXXtDXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pages"
      ],
      "metadata": {
        "id": "irVPbGdwBIkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 0_Detector.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Detector de Generos Musicales🎵\",\n",
        "    page_icon=\"🎼\",\n",
        ")\n",
        "\n",
        "st.write(\"# Bienvenido al detector de géneros musicales.🎼\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    ### Este panel interactivo en Streamlit te permitirá examinar un enlace de YouTube para determinar si la canción corresponde al género pop o vallenato.Emplearemos la Transformada Rápida de Fourier (FFT) para estudiar el espectro de frecuencias de la música y así reconocer rasgos distintivos de cada estilo musical.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "4QFb8vF2Gw_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pages/1_🎵_Clasificador_Musical.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import joblib\n",
        "import subprocess\n",
        "import yt_dlp as youtube_dl\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.fft import rfft\n",
        "\n",
        "# --- CONFIGURACIONES\n",
        "SEGUNDO_INICIO = 0\n",
        "DURACION = 10\n",
        "\n",
        "# --- CARGA DEL MODELO\n",
        "@st.cache_resource\n",
        "def cargar_modelo():\n",
        "    modelo = joblib.load(\"modelo/knn_genre_detector.pkl\")\n",
        "    return modelo\n",
        "\n",
        "# --- DESCARGA Y CONVERSIÓN\n",
        "def descargar_y_convertir(url: str, nombre_salida: str = \"fragmento_usuario\"):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': f\"{nombre_salida}.mp3\",\n",
        "        'quiet': True,\n",
        "    }\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "    subprocess.call([\n",
        "        'ffmpeg', '-y',\n",
        "        '-ss', str(SEGUNDO_INICIO),\n",
        "        '-t', str(DURACION),\n",
        "        '-i', f\"{nombre_salida}.mp3\",\n",
        "        '-ar', '48000',\n",
        "        '-ac', '2',\n",
        "        f\"{nombre_salida}.wav\"\n",
        "    ])\n",
        "    os.remove(f\"{nombre_salida}.mp3\")\n",
        "    return f\"{nombre_salida}.wav\"\n",
        "\n",
        "# --- PREDICCIÓN\n",
        "def predecir_genero(path_wav, modelo):\n",
        "    fs_ref = modelo['fs']\n",
        "    fmax_idx = modelo['fmax_idx']\n",
        "    scaler = modelo['scaler']\n",
        "    knn = modelo['knn_model']\n",
        "\n",
        "    x, fs_file = sf.read(path_wav)\n",
        "    if fs_file != fs_ref:\n",
        "        raise ValueError(f\"Frecuencia esperada: {fs_ref} Hz, encontrada: {fs_file} Hz.\")\n",
        "\n",
        "    if x.ndim == 1:\n",
        "        x = x[:fs_ref * DURACION]\n",
        "        fft_mag = np.abs(rfft(x))\n",
        "    else:\n",
        "        x = x[:fs_ref * DURACION, :]\n",
        "        fft0 = np.abs(rfft(x[:, 0]))\n",
        "        fft1 = np.abs(rfft(x[:, 1]))\n",
        "        fft_mag = (fft0 + fft1) / 2\n",
        "\n",
        "    fft_mag = fft_mag[:fmax_idx].reshape(1, -1)\n",
        "    fft_norm = scaler.transform(fft_mag)\n",
        "    pred = knn.predict(fft_norm)[0]\n",
        "    return int(pred)\n",
        "\n",
        "# --- INTERFAZ STREAMLIT\n",
        "st.title(\"🎵 Clasificador de Géneros Musicales\")\n",
        "st.write(\"Envía el link de una canción de YouTube (solo audio) y detectaremos si es **Pop** o **Vallenato**.\")\n",
        "st.markdown(f\"🎧 Este detector analiza un fragmento de `{DURACION}` segundos desde el segundo `{SEGUNDO_INICIO}` de la canción.\")\n",
        "\n",
        "modelo = cargar_modelo()\n",
        "url = st.text_input(\"🔗 Link de YouTube\")\n",
        "\n",
        "if url:\n",
        "    try:\n",
        "        st.info(\"🎧 Descargando y procesando audio...\")\n",
        "        wav_path = descargar_y_convertir(url)\n",
        "        genero = predecir_genero(wav_path, modelo)\n",
        "        st.success(f\"🎶 Género detectado: {'Pop' if genero == 1 else 'Vallenato'}\")\n",
        "        audio_file = open(wav_path, 'rb')\n",
        "        st.audio(audio_file.read(), format='audio/wav')\n",
        "        audio_file.close()\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Error al procesar el audio: {e}\")"
      ],
      "metadata": {
        "id": "-wYFlejRGz0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 1_🎵_Clasificador_Musical.py pages/"
      ],
      "metadata": {
        "id": "RBRH74ngG4C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "#Ejecutar Streamlit\n",
        "!streamlit run 0_Detector.py &>/content/logs.txt & #Cambiar 0_👋_Hello.py por el nombre de tu archivo principal\n",
        "\n",
        "#Exponer el puerto 8501 con Cloudflare Tunnel\n",
        "!cloudflared tunnel --url http://localhost:8501 > /content/cloudflared.log 2>&1 &\n",
        "\n",
        "#Leer la URL pública generada por Cloudflare\n",
        "import time\n",
        "time.sleep(15)  # Esperar que se genere la URL\n",
        "\n",
        "import re\n",
        "found_context = False  # Indicador para saber si estamos en la sección correcta\n",
        "\n",
        "with open('/content/cloudflared.log') as f:\n",
        "    for line in f:\n",
        "        #Detecta el inicio del contexto que nos interesa\n",
        "        if \"Your quick Tunnel has been created\" in line:\n",
        "            found_context = True\n",
        "\n",
        "        #Busca una URL si ya se encontró el contexto relevante\n",
        "        if found_context:\n",
        "            match = re.search(r'https?://\\S+', line)\n",
        "            if match:\n",
        "                url = match.group(0)  #Extrae la URL encontrada\n",
        "                print(f'Tu aplicación está disponible en: {url}')\n",
        "                break  #Termina el bucle después de encontrar la URL"
      ],
      "metadata": {
        "id": "cSPvLIspG6FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "res = input(\"Digite (1) para finalizar la ejecución del Dashboard: \")\n",
        "\n",
        "if res.upper() == \"1\":\n",
        "    os.system(\"pkill streamlit\")  # Termina el proceso de Streamlit\n",
        "    print(\"El proceso de Streamlit ha sido finalizado.\")"
      ],
      "metadata": {
        "id": "4rwVrBUoG_U2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}